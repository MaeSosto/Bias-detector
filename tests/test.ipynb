{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=q9NS5WpfkrU\n",
    "- https://towardsdatascience.com/masked-language-modelling-with-bert-7d49793e5d2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# inizialize two models the tokenizer and model:\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = (\"After Abraham Lincoln won the November 1860 presidential [MASK] on an \"\n",
    "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
    "        \"secession from the country to form the Confederacy. War broke out in \"\n",
    "        \"April 1861 when secessionist forces [MASK] Fort Sumter in South \"\n",
    "        \"Carolina, just over a month after Lincoln's inauguration. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to tokenize the text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,   103,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,   103,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.input_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "101 = serialize or classifier token \n",
    "102 = separate token\n",
    "103 = mask token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but here we masked already the words, so now we want to run the test again without masking words and let them mask by BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text = (\"After Abraham Lincoln won the November 1860 presidential election on an \"\n",
    "        \"anti-slavery platform, an initial seven slave states declared their \"\n",
    "        \"secession from the country to form the Confederacy. War broke out in \"\n",
    "        \"April 1861 when secessionist forces attacked Fort Sumter in South \"\n",
    "        \"Carolina, just over a month after Lincoln's inauguration. \")# we want to tokenize the text\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "inputs.keys()\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,  4161,  2037, 22965,  2013,  1996,  2406,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,  7680,  3334,  1999,  2148,  3792,\n",
       "          1010,  2074,  2058,  1037,  3204,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we can create our target labels \n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0640, 0.9273, 0.7990, 0.2019, 0.4416, 0.7705, 0.3014, 0.7743, 0.1864,\n",
       "         0.7891, 0.8058, 0.4950, 0.4786, 0.9443, 0.6866, 0.5617, 0.3762, 0.3233,\n",
       "         0.9271, 0.2694, 0.5437, 0.3370, 0.1466, 0.2732, 0.3592, 0.7236, 0.7103,\n",
       "         0.1276, 0.3324, 0.7691, 0.5724, 0.7222, 0.7576, 0.7438, 0.2254, 0.9400,\n",
       "         0.9525, 0.4063, 0.8413, 0.5576, 0.5895, 0.3944, 0.8323, 0.9092, 0.3823,\n",
       "         0.0206, 0.3786, 0.4398, 0.0536, 0.3325, 0.1558, 0.0403, 0.2798, 0.1299,\n",
       "         0.0833, 0.6052, 0.3130, 0.9727, 0.8925, 0.2651, 0.7212, 0.0032]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we wanto to mask a random numbers of ids \n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "rand.shape\n",
    "rand\n",
    "#now they are number between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False, False, False, False,  True, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True, False, False,  True, False,\n",
       "         False,  True, False,  True,  True, False, False, False, False, False,\n",
       "         False,  True]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to select a random 15% of those \n",
    "mask_arr = rand < 0.15\n",
    "mask_arr\n",
    "#later on the true token are the one that we want to mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True, False]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#but we don't want to mask the serialize and the separate token\n",
    "(inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "#so now the last token is not masked, perfect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False,  True, False, False, False, False,  True, False, False,\n",
       "         False, False, False, False, False, False, False, False, False, False,\n",
       "         False, False, False, False, False,  True, False, False,  True, False,\n",
       "         False,  True, False,  True,  True, False, False, False, False, False,\n",
       "         False, False]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so we can just use this formula from the beginning\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102)\n",
    "mask_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[22], [27], [45], [48], [51], [53], [54]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we want to have the index position of all the true value \n",
    "mask_arr[0].nonzero().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 27, 45, 48, 51, 53, 54]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#but this way we have a list in a nother list so we can use this function\n",
    "selection = torch.flatten(mask_arr[0].nonzero()).tolist()\n",
    "selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2044,  8181,  5367,  2180,  1996,  2281,  7313,  4883,  2602,\n",
       "          2006,  2019,  3424,  1011,  8864,  4132,  1010,  2019,  3988,  2698,\n",
       "          6658,  2163,   103,  2037, 22965,  2013,  1996,   103,  2000,  2433,\n",
       "          1996, 18179,  1012,  2162,  3631,  2041,  1999,  2258,  6863,  2043,\n",
       "         22965,  2923,  2749,  4457,  3481,   103,  3334,  1999,   103,  3792,\n",
       "          1010,   103,  2058,   103,   103,  2044,  5367,  1005,  1055, 17331,\n",
       "          1012,   102]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we want to use this selection to select a certain number / specific indices within our input id tensor\n",
    "inputs.input_ids[0, selection] = 103\n",
    "inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9852, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so now we can pass all of this into our model and the model will calculate our loss and logic as we saw before\n",
    "outputs = model(**inputs)\n",
    "outputs.keys()\n",
    "outputs.loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:52:10) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c431e0593e1ee77f96bd6f746b63b987ead1ae8f9402a6438f4058638187923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
