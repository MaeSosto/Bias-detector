{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install pandas\n",
    "# %pip install torch\n",
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, AutoModelForMaskedLM, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import re\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.0\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCsv(file):\n",
    "    texts = []\n",
    "    text = \"\"\n",
    "    line = 0\n",
    "    try:\n",
    "        for index,row in file.iterrows():\n",
    "        #with open(os.path.join(train_dir, a_file)) as instream:\n",
    "        #for line in instream:\n",
    "            #text += line\n",
    "            texts.append(row.loc['content'])\n",
    "            line = index\n",
    "    except UnicodeDecodeError:\n",
    "      print(f\"Unicode error for this file {file}\")\n",
    "    return texts, index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../Twitter Scraper/results/female refugee_tweet.csv'\n",
    "templates = pd.read_csv(file_path, sep=\",\")\n",
    "texts, rows = processCsv(templates.copy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating hugging face dataset from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_len = rows #dictionary lenght\n",
    "texts_dict = {'text': [t for t in texts[:ds_len]]} #create the dictionary\n",
    "ds = Dataset.from_dict(texts_dict) #dataset created by the dictionary\n",
    "ds = ds.train_test_split(test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015789031982421875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#1",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d0091b7b3c48459538ec92d9a575a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016591787338256836,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#0",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4346cfb59bd4514b2a4cf7a5e225a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016284942626953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#0",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b60c0380f14d1f93d27a1a23f20008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016160964965820312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#1",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20ae233d4054f3b9b9578c4d436bdf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenised_ds = ds.map(lambda batch: tokenizer(batch['text']), batched=True, num_proc=2, remove_columns=['text']) #take all the text data and tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(batch):\n",
    "  concat_text = {k: sum(batch[k], []) for k in batch.keys()} #unpack all the items in one large list\n",
    "  total_length = len(concat_text[list(batch.keys())[0]])\n",
    "  total_length = (total_length // block_size) * block_size\n",
    "  result = {k: [t[i: i + block_size] for i in range(0, total_length, block_size)] for k, t in concat_text.items()}\n",
    "  result['labels'] = result['input_ids'].copy()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01655125617980957,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#0",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbbb56a5d5e840eb865a42a5e48e36c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016772747039794922,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#1",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da85e99d77a84104942f1944c8f64474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015387773513793945,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#0",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de88eaee1dc4fb78d3a5ed38b8930ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015177011489868164,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "#1",
       "rate": null,
       "total": 1,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d2ba8ad6b7461b9724359a270543a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "blocked_ds = tokenised_ds.map(group_texts, batched=True, num_proc=2, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we pass a token id to our model the input has to be masked (some of the token have to be replaced with a mask)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "#data_collator([blocked_ds.__getitem__(0)])\n",
    "#tokenizer.convert_ids_to_tokens(50264)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hugging face trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "trainer_model = AutoModelForMaskedLM.from_pretrained(model_name, return_dict=True)\n",
    "\n",
    "train_args = TrainingArguments(\"test-mlm\",\n",
    "                               disable_tqdm=False,\n",
    "                               evaluation_strategy='epoch',\n",
    "                               learning_rate=2e-5,\n",
    "                               weight_decay=0.01,\n",
    "                               num_train_epochs=3,\n",
    "                               per_device_train_batch_size = 32,\n",
    "                               save_steps=20000)\n",
    "\n",
    "\n",
    "trainer = Trainer(model=trainer_model, args=train_args, train_dataset=blocked_ds['train'], eval_dataset=blocked_ds['test'], data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mae/opt/miniconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 195\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21\n",
      "  Number of trainable parameters = 109514298\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00809478759765625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 21,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c8e996b328e43d3b3b884b3c68bb928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004019975662231445,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a823b253338f4d2c940fb3585c32b722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4170923233032227, 'eval_runtime': 6.2947, 'eval_samples_per_second': 21.129, 'eval_steps_per_second': 2.701, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0038530826568603516,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b564f3a5fcf4ca29b092c839ab535d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.488988161087036, 'eval_runtime': 6.457, 'eval_samples_per_second': 20.598, 'eval_steps_per_second': 2.633, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 133\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0038290023803710938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a4f97254ca4e3580692b69fea30d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3103280067443848, 'eval_runtime': 6.307, 'eval_samples_per_second': 21.088, 'eval_steps_per_second': 2.695, 'epoch': 3.0}\n",
      "{'train_runtime': 124.9142, 'train_samples_per_second': 4.683, 'train_steps_per_second': 0.168, 'train_loss': 3.600007556733631, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=3.600007556733631, metrics={'train_runtime': 124.9142, 'train_samples_per_second': 4.683, 'train_steps_per_second': 0.168, 'train_loss': 3.600007556733631, 'epoch': 3.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "#trainer.evaluate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrasentence Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntrasentenceEvaluator():\n",
    "    \n",
    "    def __init__(self, data, choices, model_name, model):\n",
    "        self.data = data\n",
    "        self.choices = choices\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.process_sentences()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.sent_encodings, self.word_encodings, self.mask_idxs = self.make_encodings() #store the encodings\n",
    "        #self.model = AutoModelForMaskedLM.from_pretrained(model)\n",
    "    \n",
    "    #Function to make predictions and calculate how often the biased words are chosen\n",
    "    def run_model_and_evaluate(self):\n",
    "        output = self.make_predictions()\n",
    "        # self.bias = self.get_bias(output) #how often do we get the bias\n",
    "        self.get_bias(output)\n",
    "\n",
    "    #Insert the candidates words inside the sentences\n",
    "    def process_sentences(self,s='______'):\n",
    "        candidate_sentence = []\n",
    "        for index,row in self.data.iterrows():\n",
    "            candidate_sentence.append([re.sub(s,row.loc[c], row.loc['sentence']) for c in self.choices.keys()]) #replace s with candidate words\n",
    "        self.data.loc[:,'candidate_sentence'] = candidate_sentence\n",
    "    \n",
    "    #find the mask indices for the encoded sentence.\n",
    "    def get_sublist_idxs_in_list(self, word, sentence):\n",
    "        possibles = np.where(sentence==word[0])[0] #where my sentence is equal to my word\n",
    "        for p in possibles: #loop over the possibilities\n",
    "            check = sentence[p:p+len(word)] #if the word is based on two tokens then I'm gonna look for them \n",
    "            if np.all(check == word):\n",
    "                return list(range(p,(p+len(word)))) #return back the positions of the tokens\n",
    "    \n",
    "    #Function to make encodings: We go over all candidate sentences and encode the words and look for the indices of the placed words.\n",
    "    def make_encodings(self): \n",
    "        sent_encoding = [] #tokenized sentenced\n",
    "        word_encoding = [] #tokenized words\n",
    "        mask_idxs = [] #the indexes where the tokens of the choices are, i.e. where the <mask> should be into the candidates sentences\n",
    "        for index,row in self.data.iterrows():\n",
    "            _sent_encoding,_word_encoding,_mask_idxs=[],[],[] #sublists, we have 3 for each sentences\n",
    "            for i,(word,sentence) in enumerate(zip(row[self.choices.keys()],row.loc['candidate_sentence'])): #for each sentences we creted in the previous function\n",
    "                encoded_word = self.tokenizer.encode(str(\" \"+ word),add_special_tokens=False) #Roberta is greedy, needs space in front of a word to realize that it is a new word and not part of the one in front\n",
    "                encoded_sent = self.tokenizer.encode_plus(sentence, add_special_tokens = True, return_tensors = 'pt', padding='max_length', max_length=128, return_attention_mask=True)\n",
    "                tokens_to_mask_idx = self.get_sublist_idxs_in_list(np.array(encoded_word),np.array(encoded_sent['input_ids'][0])) #go through encoded_sent and find position of encoded_word\n",
    "                encoded_sent['input_ids'][0][tokens_to_mask_idx] = self.tokenizer.mask_token_id #replace tokens with mask_token, since now we are working with tokens\n",
    "                _sent_encoding.append(encoded_sent)\n",
    "                _word_encoding.append(encoded_word)\n",
    "                _mask_idxs.append(tokens_to_mask_idx)\n",
    "            sent_encoding.append(_sent_encoding)\n",
    "            word_encoding.append(_word_encoding)\n",
    "            mask_idxs.append(_mask_idxs)\n",
    "        return sent_encoding , word_encoding , mask_idxs\n",
    "    \n",
    "    #Function to make predictions:\n",
    "    # We go over all sentences with help of the made encoding and see which placed words in the candidate sentences return the highest probability of being chosen.\n",
    "    # We also see which words the mask filler, i.e. our model, would choose itself for the masked token.\n",
    "    def make_predictions(self):\n",
    "        output = [] #we want what option with highest probability has been chosen\n",
    "        for q_idx, (w, s, m) in enumerate(zip(self.word_encodings, self.sent_encodings, self.mask_idxs)):\n",
    "            predictions =[]\n",
    "            candidate_input_ids = torch.stack([inp_ids['input_ids'].squeeze(0) for inp_ids in s]) #we create batch so instead do precition one by one, the model can predict the whole batch, we create a batch for each sentence \n",
    "            candidate_attention_masks = torch.stack([am['attention_mask'].squeeze(0) for am in s])\n",
    "            candidate_logits = self.model(candidate_input_ids, attention_mask=candidate_attention_masks).logits #where logits is  raw output of the model -> prediction\n",
    "            # -> output shape: 3 * num of tokens*vocab size, e.g. a prediction over the vocabulary for each token in each candidate question\n",
    "            # -> probability distribution over the whole vocab size\n",
    "            for idx, (token, mask_idxs) in enumerate(zip(w, m)): #for each of the 3 candidate sentences, we need to pick out the token that we masked in the sentence\n",
    "                mask_token_logits = candidate_logits[idx, mask_idxs, token] # here we want to find the raw prediction for the candidate word\n",
    "                candidate_score = float(torch.mean(mask_token_logits)) #if we have more than one mask this is our \"pseudo accuracy\"\n",
    "                predictions.append(candidate_score)\n",
    "            #print(f\"iprediction: {q_idx}, values: {predictions}\")\n",
    "            output.append(np.argmax(predictions) + 1) #start the keys for the choices at 1 as well > returns the choice that is chosen as an answer, we don't need that\n",
    "        #print(output)\n",
    "        return output\n",
    "    \n",
    "    #Function to see how often the biased words were chosen.\n",
    "    def get_bias(self,predictions):\n",
    "        biased, unbiased, unrelated = 0, 0, 0\n",
    "        for pred in predictions:\n",
    "            if pred == 1:\n",
    "                biased +=1\n",
    "            if pred == 2:\n",
    "                unbiased += 1\n",
    "            if pred == 3:\n",
    "                unrelated += 1\n",
    "        print(f\"biased: {biased}\")\n",
    "        print(f\"unbiased: {unbiased}\")\n",
    "        print(f\"unrelated: {unrelated}\")\n",
    "        self.print_graph(biased, unbiased, unrelated)\n",
    "    \n",
    "    def print_graph(self, biased, unbiased, unrelated):\n",
    "        data = {\n",
    "            'Biased':biased,\n",
    "            'Unbiased':unbiased,\n",
    "            'Unrelated':unrelated\n",
    "        }\n",
    "        courses = list(data.keys())\n",
    "        values = list(data.values())\n",
    "        \n",
    "        fig = plt.figure(figsize = (10, 5))\n",
    "        \n",
    "        # creating the bar plot\n",
    "        plt.bar(courses, values, color ='maroon',\n",
    "                width = 0.4)\n",
    "        \n",
    "        plt.xlabel(\"Choices\")\n",
    "        plt.ylabel(\"Number of sentence\")\n",
    "        plt.title(f\"Intrasentence test - {self.model_name} (Pre-trained)\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the intrasentence evaluator on the pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biased: 21\n",
      "unbiased: 7\n",
      "unrelated: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAFNCAYAAABFbcjcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAn+0lEQVR4nO3deZhlVXnv8e9PZhEZQouANCASEkRA0xIVAziggANq9AoxDqhpNWr0xiTgcB1ijBqjiV5ULioREwKOGBQiEBUQhTDZIAgIIkrbCA0yKyrw3j/2qngoajjd1KnaXfX9PM95au+19vDufc4+56219pCqQpIkSf3wgLkOQJIkSb9lciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5J6J8k+SZbP8jq3S1JJ1p7N9c5HSa5O8tQp6p+W5MuzGNL9kuRFSU4Z0bJPS/LKNvzsJMeNYj1as5icaY0y3Zf+uGn/50uvT/qaBCT5dJK/m4Hl9G775iLZ05T+Hnjf2Ej7vNyR5PYkP03yoSRrzcSKZuJzXVXHVNXTZiKeadZzArBLkl1HvS71m8mZFqw+JQ8andl4n/0sDS/JY4GNq+rscVW7VdWDgKcAfwL82QTzzvh+7uF7dyywdK6D0NwyOdMaK8nLkpyZ5B+T3JTkR0n2b3XvAf4IOLz9N354K68kr01yBXBFK/twkmuS3Jrk/CR/NLCOPZKc1+quS/KhgbrHJflOkpuTXJhkn4G605K8O8m3k9yW5JQkm7fqM9rfm1tsj2/zvDzJpW1bTk6y7cDyKsmrk1zR6j+aJAP1f9bmvS3J95M8ppVvleSLSVa2/fMXk+zLpcCLgL9pMX1luvmn2DcTbt/qSPKWJDe0FtMXDZSv1973n7R1H5Fkg1a3T5LlSQ5N8jO6H7v/BLZq8dyeZKsh1n3IwD69KsmrBurGr+NfkmyQ5Oj2/lya5G8GW+uGfS8Glz+u7H9ajZO8M8nnknymxXdJkiUD026T5EttXTcOfP53SPKNVnZDkmOSbDIw36HpWq5uS3J5kqe08gckOSzJD9u8n0uy2cB8L07y41b31ml27f7A6ZNVVtVlwLfoWpDGWmFfkeQnwDfa+iY9Vsbts8k+11e3bb0IuCPJ2gPbN3YMPXdgOS9LcubA+HTH41TH8r5JLktyS3tf/me+5jTgGdPsQ813VeXL1xrzAq4GntqGXwb8hu4/7LWA1wArgLT604BXjpu/gFOBzYANWtmfAr8DrA28CfgZsH6rOwt4cRt+EPC4Nrw1cCNwAN0/Ofu28UUD6/4h8LvABm38fa1uuxbH2gNxPQe4Evj9FsfbgO+Mi/urwCbAYmAlsF+rewHwU+CxdF/0jwC2bXGdD7wdWBd4OHAV8PRJ9u2ngb8bGJ9y/in2zX22bzXe532Au4APAesBewN3ADu1+n8GTmjv40bAV4D3jpv3/W3eDVrZ8mnWea+46X4gd2j7dG/gF8BjpljH++iSjk2BhwEXja1zNd6L+8TLvT/77wTupPv8rQW8Fzi71a0FXAj8E7AhsD7wxFb3CLrP6nrAIrpE+p9b3U7ANcBWA/tjhzb8RuDstl3rAf8POLbV7QzcDuzV6j7U9s1TJ9m2zwN/PcFx+YiB5f0MeMXAe/KZti0bMM2xMt3nemBfLgO24bffAy8Atmrv1QvpPm9bDnzXnDnk8ThpfMDmwK3A84F1gP/d9tUrB5a9WVv+g+f6+9bX3L3mPABfvlblxX2TsysH6h7YvtQe2sZPY+Lk7MnTrOMmui4W2o/Xu4DNx01zKPCv48pOBl46sO63DdT9OfC1Njz2gzOYnP0n8IqB8QfQJQPbDsT9xIH6zwGHDaz3DRNsxx8CPxlX9mbgXybZ7nv9iE03/xT75j7btxrv8z7tR2vDcdv8f+iSpTtoiUOrezzwo4F5f01LsAfKVik5m6D+y2P7eZJ13CvZAl7Jb5OzVX0v7hMv903O/mugbmfglwP7YuUw+58ukfhuG34EcD3wVGCdcdNdCjxlYHxLun+M1qZLOI8bqNuw7ZvJkrNTgVePKyu6pOUmun9q/o7uGBh7Tx4+7LEy3ed6YF++fJp9sww4sA2/jPsmZ5Mdj5PGB7yElkS3ugDLuXdytk5b/uLVPX58rfkvuzW1pvvZ2EBV/aINPmiaea4ZHEnyptYFcUuSm4GN6f7Dhe6/998FLktybpJntvJtgRek69K8uc33RLofrfvERvflPFVc2wIfHljWz+m+uLceYnnb0P2gTbTMrcbF+BZgiyniWJX5J9s30xroXrw9yeJJJrupqu4YGP8xXcvGIrpE/PyBuL7WysesrKo7708MSfZPcnaSn7d1HMBvPxcTrWMr7v3ZGhyecl8OuT/GG/95WD/d+VPbAD+uqrsm2KaHJDmudV3eCvzb2DZV1ZV0LWTvBK5v0411/24LHD8Q+6XA3S3+e213e89unCLum+haO8d7TFVtWlU7VNXbquqegbrx+3LCYyVdN/jYfjxiihjGL5MkL0mybGC5u3Dv93u8yY7HqY7l8fuqxsfBb/fNzdPEr3msbydCSjOppitPd37ZoXQnIV9SVfckuYl2HkhVXQEcnOQBwPOALyT5Hbov1H+tqvuctLyacV0DvKeqjlmN5V1D1/02UfmPqmrH1Yxryvmn2DeT7ffBeadLoAE2TbLhQIK2GLgYuAH4JfDIqvrpZKuYZvw+MSTZbmB4PeCLdC0d/1FVv0l364fB84PGL/Naum6/77fxbQbqptuX42PZgi4BHRtfi3snn1O5BlicZO0JErT3trh3raobkzwHOHwgjn8H/j3Jg+m6Lt8PvLgt8+VV9e3xK0tyLV0X3tj4A+lOE5jMRXRJ/aoY3NdTHSvfobsSdLJ5Jyxv54R9gu574KyqujvJMu57PtgwJo0vyY4MfC7aeWrbjJvs94Grq+rW1Vi35glbzjSfXUd3bs9UNqLrPlsJrJ3k7cCDxyqT/GmSRe2/+Jtb8d10LQ7PSvL0JGslWT/dSdwPGyKulcA942I7Anhzkke29W6c5AVDLAvgk8BfJfmDdB7RfmzOAW5Nd+LzBi3OXdJdLTeR8ftryvmn2DcTbd/qeleSdVsS/Uzg8219nwD+KclDWixbJ3n6FMu5DvidJBsPud516c6fWgncle5Ck+lupfA5uvdw0yRbA68bqFvV9+IHdC1hz0iyDt15S+sNGfs5dIni+5Js2D6be7a6jejOD7u5xfjXYzMl2SnJk1tieiddAnx3qz4CeE/7XJFkUZIDW90XgGcmeWKSdYG/ZerflpPozuFbXat6rAzzPbAhXbK2si3zELqWs5mO70TgkUme11o5/wJ46Lj596brGtUCZnKm+ezDwPPTXTH1kUmmOZnui/AHdN1md3Lvbob9gEuS3N6Wd1BV3VlV1wAH0nVNrWzz/DVDHFOt+/U9wLdb18fjqup4ulaK41p308V0V7VNq6o+35b378BtdOdGbVZVdwPPAnYHfkTX4vRJum7biXwK2LnF9OUh5p9s39xn+4bZjgn8jK4LbAVwDN15Spe1ukPpTro+u+2v/6I7oX1Cbb5jgataTFNerVlVt9H9cH6uxfAndBcgTOVv6c4f+lGL5wvAr9ryVum9qKpb6M5T/CTdxR53tGVPa2BdjwB+0uZ7Yat+F/AY4Ba6ROFLA7OuR3dRww10+/4hdJ9v6N7fE4BTktxGd3HAH7b1XQK8lu7zdy3d/po01qq6ALglyR8Osz0TzL+qx8q9PteTLPP7wAfpLnK5DngUcJ9WwvsbX1XdQHfhwfvoun53nGA9B9O1WmoBG7uqTZI0g5K8hi5hvT+tRPNSkqcBf15Vz5nrWPokybPoroD+X3Mdi+aWyZkkzYAkW9J1n51F1yJyInB4Vf3zXMYlac3jBQGSNDPWpeuO2p7uHLzjgI/NZUCS1ky2nEmSJPWIFwRIkiT1iMmZJElSj8yrc84233zz2m677eY6DEmSpGmdf/75N1TVfW4wPa+Ss+22247zzjtvrsOQJEmaVpIfT1Rut6YkSVKPmJxJkiT1iMmZJElSj5icSZIk9YjJmSRJUo+YnEmSJPWIyZkkSVKPmJxJkiT1iMmZJElSj5icSZIk9YjJmSRJUo/Mq2drzoZ3JXMdwrzyjqq5DkGSpF6x5UySJKlHTM4kSZJ6xORMkiSpR0zOJEmSesTkTJIkqUdMziRJknrE5EySJKlHRpacJdkmyTeTXJrkkiRvaOWbJTk1yRXt76aTzL9fksuTXJnksFHFKUmS1CejbDm7C3hTVf0+8DjgtUl2Bg4Dvl5VOwJfb+P3kmQt4KPA/sDOwMFtXkmSpHltZMlZVV1bVRe04duAS4GtgQOBo9tkRwPPmWD2PYArq+qqqvo1cFybT5IkaV6blXPOkmwHPBr4b2CLqroWugQOeMgEs2wNXDMwvryVSZIkzWsjT86SPAj4IvDGqrp12NkmKJvwIYxJliY5L8l5K1euXN0wJUmSemGkyVmSdegSs2Oq6kut+LokW7b6LYHrJ5h1ObDNwPjDgBUTraOqjqyqJVW1ZNGiRTMXvCRJ0hwY5dWaAT4FXFpVHxqoOgF4aRt+KfAfE8x+LrBjku2TrAsc1OaTJEma10bZcrYn8GLgyUmWtdcBwPuAfZNcAezbxkmyVZKTAKrqLuB1wMl0FxJ8rqouGWGskiRJvbD2qBZcVWcy8bljAE+ZYPoVwAED4ycBJ40mOkmSpH7yCQGSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CNrj2rBSY4CnglcX1W7tLLPAju1STYBbq6q3SeY92rgNuBu4K6qWjKqOCVJkvpkZMkZ8GngcOAzYwVV9cKx4SQfBG6ZYv4nVdUNI4tOkiSph0aWnFXVGUm2m6guSYD/BTx5VOuXJElaE83VOWd/BFxXVVdMUl/AKUnOT7J0FuOSJEmaU6Ps1pzKwcCxU9TvWVUrkjwEODXJZVV1xkQTtuRtKcDixYtnPlJJkqRZNOstZ0nWBp4HfHayaapqRft7PXA8sMcU0x5ZVUuqasmiRYtmOlxJkqRZNRfdmk8FLquq5RNVJtkwyUZjw8DTgItnMT5JkqQ5M7LkLMmxwFnATkmWJ3lFqzqIcV2aSbZKclIb3QI4M8mFwDnAiVX1tVHFKUmS1CejvFrz4EnKXzZB2QrggDZ8FbDbqOKSJEnqM58QIEmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9MrLkLMlRSa5PcvFA2TuT/DTJsvY6YJJ590tyeZIrkxw2qhglSZL6ZpQtZ58G9pug/J+qavf2Oml8ZZK1gI8C+wM7Awcn2XmEcUqSJPXGyJKzqjoD+PlqzLoHcGVVXVVVvwaOAw6c0eAkSZJ6aujkLMmGM7TO1yW5qHV7bjpB/dbANQPjy1uZJEnSvDdtcpbkCUm+D1zaxndL8rHVXN/HgR2A3YFrgQ9OtMoJymqK+JYmOS/JeStXrlzNsCRJkvphmJazfwKeDtwIUFUXAnutzsqq6rqquruq7gE+QdeFOd5yYJuB8YcBK6ZY5pFVtaSqlixatGh1wpIkSeqNobo1q+qacUV3r87Kkmw5MPpc4OIJJjsX2DHJ9knWBQ4CTlid9UmSJK1p1h5immuSPAGoliz9Ba2LcypJjgX2ATZPshx4B7BPkt3puimvBl7Vpt0K+GRVHVBVdyV5HXAysBZwVFVdsqobJkmStCYaJjl7NfBhupPylwOnAK+dbqaqOniC4k9NMu0K4ICB8ZOA+9xmQ5Ikab6bNjmrqhuAF81CLJIkSQveMFdrHp1kk4HxTZMcNdKoJEmSFqhhLgjYtapuHhupqpuAR48sIkmSpAVsmOTsAYM3i02yGcOdqyZJkqRVNEyS9UHgO0m+0MZfALxndCFJkiQtXMNcEPCZJOcDT6K7e//zqur7I49MkiRpARq2e/Iy4Kax6ZMsrqqfjCwqSZKkBWra5CzJ6+luIHsd3ZMBQncT2V1HG5okSdLCM0zL2RuAnarqxlEHI0mStNANc7XmNcAtow5EkiRJw7WcXQWcluRE4FdjhVX1oZFFJUmStEANk5z9pL3WbS9JkiSNyDC30ngXQJINq+qO0YckSZK0cA3zbM3HJ/k+cGkb3y3Jx0YemSRJ0gI0zAUB/ww8HbgRoKouBPYaYUySJEkL1jDJGVV1zbiiu0cQiyRJ0oI3zAUB1yR5AlBJ1gX+gtbFKUmSpJk1TMvZq4HXAlsDy4HdgT8fYUySJEkL1jAtZztV1YsGC5LsCXx7NCFJkiQtXMO0nP3fIcskSZJ0P03acpbk8cATgEVJ/nKg6sHAWqMOTJIkaSGaqltzXeBBbZqNBspvBZ4/yqAkSZIWqkmTs6o6HTg9yaer6seruuAkRwHPBK6vql1a2QeAZwG/Bn4IHFJVN08w79XAbXS37Lirqpas6volSZLWRMOcc7ZekiOTnJLkG2OvIeb7NLDfuLJTgV2qalfgB8Cbp5j/SVW1u4mZJElaSIa5WvPzwBHAJ1mFm89W1RlJthtXdsrA6NnYPSpJknQvwyRnd1XVx0ew7pcDn52kroBTkhTw/6rqyBGsX5IkqXeGSc6+kuTPgeOBX40VVtXPV3elSd4K3AUcM8kke1bViiQPAU5NcllVnTHJspYCSwEWL168uiFJkiT1wjDJ2Uvb378eKCvg4auzwiQvpbtQ4ClVVRNNU1Ur2t/rkxwP7AFMmJy1VrUjAZYsWTLh8iRJktYU0yZnVbX9TK0syX7AocDeVfWLSabZEHhAVd3Whp8G/O1MxSBJktRn016tmeSBSd6W5Mg2vmOSZw4x37HAWcBOSZYneQVwON09005NsizJEW3arZKc1GbdAjgzyYXAOcCJVfW11do6SZKkNcww3Zr/ApxP97QA6B5+/nngq1PNVFUHT1D8qUmmXQEc0IavAnYbIi5JkqR5Z5j7nO1QVf8A/Aagqn4JZKRRSZIkLVDDJGe/TrIB3UUAJNmBgas2JUmSNHOG6dZ8B/A1YJskxwB7Ai8bZVCSJEkL1TBXa56a5ALgcXTdmW+oqhtGHpkkSdICNMzVmnsCd1bVicAmwFuSbDvqwCRJkhaiYc45+zjwiyS70d2I9sfAZ0YalSRJ0gI1THJ2V7uT/4HAR6rqw3T3KpMkSdIMG+aCgNuSvBn4U2CvJGsB64w2LEmSpIVpmJazF9LdOuMVVfUzYGvgAyONSpIkaYEa5mrNnwEfGhj/CZ5zJkmSNBLDtJxJkiRplpicSZIk9cikyVmSr7e/75+9cCRJkha2qc452zLJ3sCzkxzHuIedV9UFI41MkiRpAZoqOXs7cBjwMAYuCGgKePKogpIkSVqoJk3OquoLwBeS/J+qevcsxiRJkrRgDXMrjXcneTawVys6raq+OtqwJEmSFqZhHnz+XuANwPfb6w2tTJIkSTNsmMc3PQPYvaruAUhyNPBd4M2jDEySJGkhGvY+Z5sMDG88gjgkSZLEcC1n7wW+m+SbdLfT2AtbzSRJkkZimAsCjk1yGvBYuuTs0Pa8TUmSJM2wobo1q+raqjqhqv5j2MQsyVFJrk9y8UDZZklOTXJF+7vpJPPul+TyJFcmOWy4TZEkSVrzjfLZmp8G9htXdhjw9araEfh6G7+XJGsBHwX2B3YGDk6y8wjjlCRJ6o2RJWdVdQbw83HFBwJHt+GjgedMMOsewJVVdVVV/Ro4rs0nSZI0702ZnCV5wGC35AzYoqquha6rFHjIBNNsDVwzML68lUmSJM17UyZn7d5mFyZZPEvxwLgHrI+FMunEydIk5yU5b+XKlSMMS5IkafSGuZXGlsAlSc4B7hgrrKpnr8b6rkuyZVVdm2RL4PoJplkObDMw/jBgxWQLrKojgSMBlixZMmkSJ0mStCYYJjl71wyu7wTgpcD72t//mGCac4Edk2wP/BQ4CPiTGYxBkiSpt6a9IKCqTgeuBtZpw+cCF0w3X5JjgbOAnZIsT/IKuqRs3yRXAPu2cZJsleSktr67gNcBJwOXAp+rqktWY9skSZLWONO2nCX5M2ApsBmwA93J+UcAT5lqvqo6eJKq+8xXVSuAAwbGTwJOmi42SZKk+WaYW2m8FtgTuBWgqq5g4qssJUmSdD8Nk5z9qt1vDIAkazPF1ZOSJElafcMkZ6cneQuwQZJ9gc8DXxltWJIkSQvTMMnZYcBK4HvAq+jOBXvbKIOSJElaqKa9IKCq7klyNPDfdN2Zl1eV3ZqSJEkjMMzVms+guzrzh3R3798+yauq6j9HHZwkSdJCM8xNaD8IPKmqrgRIsgNwImByJkmSNMOGOefs+rHErLmKiR+7JEmSpPtp0pazJM9rg5e0u/d/ju6csxfQPSVAkiRJM2yqbs1nDQxfB+zdhlcCm44sIkmSpAVs0uSsqg6ZzUAkSZI03NWa2wOvB7YbnL6qnj26sCRJkhamYa7W/DLwKbqnAtwz0mgkSZIWuGGSszur6iMjj0SSJElDJWcfTvIO4BTgV2OFVXXByKKSJElaoIZJzh4FvBh4Mr/t1qw2LkmSpBk0THL2XODhVfXrUQcjSZK00A3zhIALgU1GHIckSZIYruVsC+CyJOdy73POvJWGJEnSDBsmOXvHyKOQJEkSMERyVlWnz0YgkiRJGu4JAbfRXZ0JsC6wDnBHVT14lIFJkiQtRNNeEFBVG1XVg9trfeCPgcNXd4VJdkqybOB1a5I3jptmnyS3DEzz9tVdnyRJ0ppkmHPO7qWqvpzksNVdYVVdDuwOkGQt4KfA8RNM+q2qeubqrkeSJGlNNEy35vMGRh8ALOG33Zz311OAH1bVj2doeZIkSWu0YVrOnjUwfBdwNXDgDK3/IODYSeoen+RCYAXwV1V1yUQTJVkKLAVYvHjxDIUlSZI0N4a5WvOQUaw4ybrAs4E3T1B9AbBtVd2e5ADgy8COk8R3JHAkwJIlS2aqRU+SJGlOTJqcTXMSflXVu+/nuvcHLqiq6yZY+K0Dwycl+ViSzavqhvu5TkmSpF6b6mrNOyZ4AbwCOHQG1n0wk3RpJnlokrThPVqcN87AOiVJknpt0pazqvrg2HCSjYA3AIcAxwEfnGy+YSR5ILAv8KqBsle39R4BPB94TZK7gF8CB1WVXZaSJGnem/KcsySbAX8JvAg4GnhMVd10f1daVb8Afmdc2REDw4dzP+6lJkmStKaa6pyzDwDPozvZ/lFVdfusRSVJkrRATdVy9ibgV8DbgLe2U8AAQndBgI9vkrTa3vXb7xTNkHd49oc0L0x1ztm0j3aSJEnSzDIBkyRJ6hGTM0mSpB4xOZMkSeoRkzNJkqQeMTmTJEnqEZMzSZKkHjE5kyRJ6hGTM0mSpB4xOZMkSeoRkzNJkqQeMTmTJEnqEZMzSZKkHjE5kyRJ6hGTM0mSpB4xOZMkSeoRkzNJkqQeMTmTJEnqEZMzSZKkHpmT5CzJ1Um+l2RZkvMmqE+SjyS5MslFSR4zF3FKkiTNtrXncN1PqqobJqnbH9ixvf4Q+Hj7K0mSNK/1tVvzQOAz1Tkb2CTJlnMdlCRJ0qjNVXJWwClJzk+ydIL6rYFrBsaXtzJJkqR5ba66NfesqhVJHgKcmuSyqjpjoD4TzFMTLagld0sBFi9ePPORSpIkzaI5aTmrqhXt7/XA8cAe4yZZDmwzMP4wYMUkyzqyqpZU1ZJFixaNIlxJkqRZM+vJWZINk2w0Ngw8Dbh43GQnAC9pV20+Drilqq6d5VAlSZJm3Vx0a24BHJ9kbP3/XlVfS/JqgKo6AjgJOAC4EvgFcMgcxClJkjTrZj05q6qrgN0mKD9iYLiA185mXJIkSX3Q11tpSJIkLUgmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9MuvJWZJtknwzyaVJLknyhgmm2SfJLUmWtdfbZztOSZKkubD2HKzzLuBNVXVBko2A85OcWlXfHzfdt6rqmXMQnyRJ0pyZ9Zazqrq2qi5ow7cBlwJbz3YckiRJfTSn55wl2Q54NPDfE1Q/PsmFSf4zySNnNzJJkqS5MRfdmgAkeRDwReCNVXXruOoLgG2r6vYkBwBfBnacZDlLgaUAixcvHl3AkiRJs2BOWs6SrEOXmB1TVV8aX19Vt1bV7W34JGCdJJtPtKyqOrKqllTVkkWLFo00bkmSpFGbi6s1A3wKuLSqPjTJNA9t05FkD7o4b5y9KCVJkubGXHRr7gm8GPhekmWt7C3AYoCqOgJ4PvCaJHcBvwQOqqqag1glSZJm1awnZ1V1JpBppjkcOHx2IpIkSeoPnxAgSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJkmS1CMmZ5IkST0yJ8lZkv2SXJ7kyiSHTVCfJB9p9RclecxcxClJkjTbZj05S7IW8FFgf2Bn4OAkO4+bbH9gx/ZaCnx8VoOUJEmaI3PRcrYHcGVVXVVVvwaOAw4cN82BwGeqczawSZItZztQSZKk2TYXydnWwDUD48tb2apOI0mSNO+sPQfrzARltRrTdBMmS+m6PgFuT3L5/YhtPtkcuGGug5jOOzPRWy31jseTNDPWiGNpFm07UeFcJGfLgW0Gxh8GrFiNaQCoqiOBI2cywPkgyXlVtWSu45DmA48naWZ4LA1nLro1zwV2TLJ9knWBg4ATxk1zAvCSdtXm44Bbqura2Q5UkiRpts16y1lV3ZXkdcDJwFrAUVV1SZJXt/ojgJOAA4ArgV8Ah8x2nJIkSXMhVROeyqU1XJKlrctX0v3k8STNDI+l4ZicSZIk9YiPb5IkSeoRk7OeSnJ3kmVJLkxyQZIntPKtknxhhOvdJ8lXR7V8aVSSbJfk4nFl70zyV1PM87Ikh09S952ZjnFg2feJVeqD1TmOVmHZ0/6+JNk9yQGrsezTksybq0BNzvrrl1W1e1XtBrwZeC9AVa2oqufPbWjS/FdVT5jrGKQ1TZL7e6Hh7nQXBC5oJmdrhgcDN8G9/6tpw99qLWuDrWtbJjmjtbxdnOSPWvnTkpzVpv18kge18v2SXJbkTOB5c7OJ0ui0/6rfn+ScJD8YOyaabZJ8LcnlSd4xMM/t7e+Dkny9HTffS3JgK98wyYmtdfviJC9s5X+Q5PQk5yc5eezRc638wiRnAa+dva2XZsZkx1Frgf58kq8Ap7Rj46gk5yb57tgxM25ZeyT5Tqv/TpKd2u21/hZ4Yfv9euFky0qyQZLjklyU5LPABrO5L0ZtLm5Cq+FskGQZsD6wJfDkCaa5Hti3qu5MsiNwLLAE+BPg5Kp6T7oHzT8wyebA24CnVtUdSQ4F/jLJPwCfaMu/EvjsqDdMmiNrV9UercvkHcBTW/kewC50t+05N8mJVXXewHx3As+tqlvbcXR2khOA/YAVVfUMgCQbJ1kH+L/AgVW1siVs7wFeDvwL8PqqOj3JB2Zhe6VRmOw4ejywa1X9PMnfA9+oqpcn2QQ4J8l/jVvOZcBe7fZaTwX+vqr+OMnbgSVV9TqAKZb1KuAXVbVrkl2BC0a83bPK5Ky/fllVuwMkeTzwmSS7jJtmHeDwJLsDdwO/28rPBY5qPxRfrqplSfYGdga+ne4RL+sCZwG/B/yoqq5o6/o3fvs4LGlNMtml52PlX2p/zwe2G6g/tapuBEjyJeCJwGByFuDvk+wF3EP3nN8tgO8B/5jk/cBXq+pb7RjdBTi1HWdrAdcm2RjYpKpOb8v8V2D/1d1QaYTuz3H08zb8NODZA+eprQ8sHre8jYGjW8NC0f2eTWSyZe0FfASgqi5KctFUG7WmMTlbA1TVWe0/9kXjqv43cB2wG10X9Z1t+jPaD8kzgH9t/6XfRHfwHDy4gJbYeT8VzQc3ApuOK9sM+FEb/lX7ezf3/u4b//kfP/4iumPvD6rqN0muBtavqh8k+QO682Pem+QU4Hjgkqp6/OAC2n/8HmdaE6zucXTHwHCAP66qez3rOskWA6PvBr5ZVc9Nsh1w2iTxTLYsmMfHlOecrQGS/B7df+A3jqvaGLi2qu4BXtymIcm2wPVV9QngU8BjgLOBPZM8ok3zwCS/S9e0vH2SHdoyD0ZaA1XV7XStVE8BSLIZXdfjmdPMum+SzZJsADwH+Pa4+o3pjqffJHkS7UHFSbai61b5N+Af6Y6zy4FFrbWbJOskeWRV3QzckuSJbZkvun9bK43G/TiOBp0MvD4tg0ry6Amm2Rj4aRt+2UD5bcBGQyzrDNpx1Fqsd12F+HrP5Ky/NmgnRC6jOw/spVV197hpPga8NMnZdF2aY/+57AMsS/Jd4I+BD1fVSroD4NjW/Hs28HtVdSddN+aJ6S4I+PFoN0saqZcAb2vHzTeAd1XVD6eZ50y6bsZlwBfHnW8GcAywJMl5dD8Gl7XyR9Gd/7IMeCvwd1X1a+D5wPuTXNiWOXbV5yHAR9sFAb9c3Q2UZsHqHEeD3k3XTXlRugvY3j3BNP9A1+L8bVrDQvNNYOexCwKmWNbHgQe137O/Ac5Zhfh6zycESJIk9YgtZ5IkST1iciZJktQjJmeSJEk9YnImSZLUIyZnkiRJPWJyJmneSvLQ9vy9Hyb5fpKTkixN8tVVXM4nk+w8qjglaZBPCJA0L7WbVh4PHF1VB7Wy3YFnreqyquqVMxudJE3OljNJ89WTgN9U1RFjBVW1DPgW3c0rv5DksiTHDNx9/ClJvpvke0mOSrJeKz8tyZI2vF+SC5JcmOTrrWzDNv25bf4DW/kjk5zTbqh5UXuOoCRNyeRM0ny1C93DmSfyaOCNwM7Aw+kebbY+8GnghVX1KLqehdcMzpRkEfAJumf97Qa8oFW9FfhGVT2WLin8QJINgVfTPaFjd2AJsHymNk7S/GVyJmkhOqeqlrfn0i4DtgN2An5UVT9o0xwN7DVuvscBZ1TVjwCq6uet/GnAYe1xN6cB6wOLgbOAtyQ5FNi2qnxsk6Rpec6ZpPnqErrnXE7kVwPDd9N9F2aIZQaY6Jl3oWtNu3xc+aVJ/ht4BnBykldW1TeGWI+kBcyWM0nz1TeA9ZL82VhBkscCe08y/WXAdkke0cZfDJw+bpqzgL2TbN+Wt1krPxl4/cC5a49ufx8OXFVVHwFOAHa931slad4zOZM0L1VVAc8F9m230rgEeCewYpLp7wQOAT6f5HvAPcAR46ZZCSwFvpTkQuCzrerdwDrARUkubuMALwQubt2dvwd8ZsY2UNK8le77S5IkSX1gy5kkSVKPmJxJkiT1iMmZJElSj5icSZIk9YjJmSRJUo+YnEmSJPWIyZkkSVKPmJxJkiT1yP8H0kMzn0CuLSoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "choices = {'bias':1, 'unbiased':2,'unrelated':3} \n",
    "file_path = 'dataset/template_intra.csv' #\"drive/MyDrive/Final_templates.csv\"#\"drive/MyDrive/New_templates.csv\"\n",
    "model_name = 'bert-large-uncased'\n",
    "templates = pd.read_csv(file_path, sep=\";\")\n",
    "evaluator = IntrasentenceEvaluator(templates.copy(), choices, model_name, trainer.model)\n",
    "evaluator.run_model_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c431e0593e1ee77f96bd6f746b63b987ead1ae8f9402a6438f4058638187923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
