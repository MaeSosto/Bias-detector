{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install pandas\n",
    "# %pip install torch\n",
    "# %pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling, AutoModelForMaskedLM, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import re\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processCsv(file):\n",
    "    texts = []\n",
    "    text = \"\"\n",
    "    line = 0\n",
    "    try:\n",
    "        for index,row in file.iterrows():\n",
    "        #with open(os.path.join(train_dir, a_file)) as instream:\n",
    "        #for line in instream:\n",
    "            #text += line\n",
    "            texts.append(row.loc['content'])\n",
    "            line = index\n",
    "    except UnicodeDecodeError:\n",
    "      print(f\"Unicode error for this file {file}\")\n",
    "    return texts, index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../Twitter Scraper/results/female refugee_tweet.csv'\n",
    "templates = pd.read_csv(file_path, sep=\",\")\n",
    "texts, rows = processCsv(templates.copy())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating hugging face dataset from text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_len = rows #dictionary lenght\n",
    "texts_dict = {'text': [t for t in texts[:ds_len]]} #create the dictionary\n",
    "ds = Dataset.from_dict(texts_dict) #dataset created by the dictionary\n",
    "ds = ds.train_test_split(test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenised_ds = ds.map(lambda batch: tokenizer(batch['text']), batched=True, num_proc=2, remove_columns=['text']) #take all the text data and tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "\n",
    "def group_texts(batch):\n",
    "  concat_text = {k: sum(batch[k], []) for k in batch.keys()} #unpack all the items in one large list\n",
    "  total_length = len(concat_text[list(batch.keys())[0]])\n",
    "  total_length = (total_length // block_size) * block_size\n",
    "  result = {k: [t[i: i + block_size] for i in range(0, total_length, block_size)] for k, t in concat_text.items()}\n",
    "  result['labels'] = result['input_ids'].copy()\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked_ds = tokenised_ds.map(group_texts, batched=True, num_proc=2, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we pass a token id to our model the input has to be masked (some of the token have to be replaced with a mask)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
    "#data_collator([blocked_ds.__getitem__(0)])\n",
    "#tokenizer.convert_ids_to_tokens(50264)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hugging face trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_model = AutoModelForMaskedLM.from_pretrained(model_name, return_dict=True)\n",
    "\n",
    "train_args = TrainingArguments(\"test-mlm\",\n",
    "                               disable_tqdm=False,\n",
    "                               evaluation_strategy='epoch',\n",
    "                               learning_rate=2e-5,\n",
    "                               weight_decay=0.01,\n",
    "                               num_train_epochs=3,\n",
    "                               per_device_train_batch_size = 32,\n",
    "                               save_steps=20000)\n",
    "\n",
    "\n",
    "trainer = Trainer(model=trainer_model, args=train_args, train_dataset=blocked_ds['train'], eval_dataset=blocked_ds['test'], data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 130\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01849222183227539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a8661f0f5247569e25ba2a0e6030ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4718515872955322, 'eval_runtime': 10.535, 'eval_samples_per_second': 12.34, 'eval_steps_per_second': 1.614, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 130\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0036919116973876953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6beefb76a7480983a50fca59c73a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2944998741149902, 'eval_runtime': 5.669, 'eval_samples_per_second': 22.932, 'eval_steps_per_second': 2.999, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 130\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002850055694580078,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 17,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00b97e7b3ed4f148c61181f8de307c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/17 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.437710762023926, 'eval_runtime': 5.7208, 'eval_samples_per_second': 22.724, 'eval_steps_per_second': 2.972, 'epoch': 3.0}\n",
      "{'train_runtime': 152.0262, 'train_samples_per_second': 3.927, 'train_steps_per_second': 0.138, 'train_loss': 3.586953662690662, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=3.586953662690662, metrics={'train_runtime': 152.0262, 'train_samples_per_second': 3.927, 'train_steps_per_second': 0.138, 'train_loss': 3.586953662690662, 'epoch': 3.0})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "#trainer.evaluate()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intrasentence Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntrasentenceEvaluator():\n",
    "    \n",
    "    def __init__(self, data, choices, model_name, model):\n",
    "        self.data = data\n",
    "        self.choices = choices\n",
    "        self.model = model\n",
    "        self.model_name = model_name\n",
    "        self.process_sentences()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.sent_encodings, self.word_encodings, self.mask_idxs = self.make_encodings() #store the encodings\n",
    "        #self.model = AutoModelForMaskedLM.from_pretrained(model)\n",
    "    \n",
    "    #Function to make predictions and calculate how often the biased words are chosen\n",
    "    def run_model_and_evaluate(self):\n",
    "        output = self.make_predictions()\n",
    "        # self.bias = self.get_bias(output) #how often do we get the bias\n",
    "        self.get_bias(output)\n",
    "\n",
    "    #Insert the candidates words inside the sentences\n",
    "    def process_sentences(self,s='______'):\n",
    "        candidate_sentence = []\n",
    "        for index,row in self.data.iterrows():\n",
    "            candidate_sentence.append([re.sub(s,row.loc[c], row.loc['sentence']) for c in self.choices.keys()]) #replace s with candidate words\n",
    "        self.data.loc[:,'candidate_sentence'] = candidate_sentence\n",
    "    \n",
    "    #find the mask indices for the encoded sentence.\n",
    "    def get_sublist_idxs_in_list(self, word, sentence):\n",
    "        possibles = np.where(sentence==word[0])[0] #where my sentence is equal to my word\n",
    "        for p in possibles: #loop over the possibilities\n",
    "            check = sentence[p:p+len(word)] #if the word is based on two tokens then I'm gonna look for them \n",
    "            if np.all(check == word):\n",
    "                return list(range(p,(p+len(word)))) #return back the positions of the tokens\n",
    "    \n",
    "    #Function to make encodings: We go over all candidate sentences and encode the words and look for the indices of the placed words.\n",
    "    def make_encodings(self): \n",
    "        sent_encoding = [] #tokenized sentenced\n",
    "        word_encoding = [] #tokenized words\n",
    "        mask_idxs = [] #the indexes where the tokens of the choices are, i.e. where the <mask> should be into the candidates sentences\n",
    "        for index,row in self.data.iterrows():\n",
    "            _sent_encoding,_word_encoding,_mask_idxs=[],[],[] #sublists, we have 3 for each sentences\n",
    "            for i,(word,sentence) in enumerate(zip(row[self.choices.keys()],row.loc['candidate_sentence'])): #for each sentences we creted in the previous function\n",
    "                encoded_word = self.tokenizer.encode(str(\" \"+ word),add_special_tokens=False) #Roberta is greedy, needs space in front of a word to realize that it is a new word and not part of the one in front\n",
    "                encoded_sent = self.tokenizer.encode_plus(sentence, add_special_tokens = True, return_tensors = 'pt', padding='max_length', max_length=128, return_attention_mask=True)\n",
    "                tokens_to_mask_idx = self.get_sublist_idxs_in_list(np.array(encoded_word),np.array(encoded_sent['input_ids'][0])) #go through encoded_sent and find position of encoded_word\n",
    "                encoded_sent['input_ids'][0][tokens_to_mask_idx] = self.tokenizer.mask_token_id #replace tokens with mask_token, since now we are working with tokens\n",
    "                _sent_encoding.append(encoded_sent)\n",
    "                _word_encoding.append(encoded_word)\n",
    "                _mask_idxs.append(tokens_to_mask_idx)\n",
    "            sent_encoding.append(_sent_encoding)\n",
    "            word_encoding.append(_word_encoding)\n",
    "            mask_idxs.append(_mask_idxs)\n",
    "        return sent_encoding , word_encoding , mask_idxs\n",
    "    \n",
    "    #Function to make predictions:\n",
    "    # We go over all sentences with help of the made encoding and see which placed words in the candidate sentences return the highest probability of being chosen.\n",
    "    # We also see which words the mask filler, i.e. our model, would choose itself for the masked token.\n",
    "    def make_predictions(self):\n",
    "        output = [] #we want what option with highest probability has been chosen\n",
    "        for q_idx, (w, s, m) in enumerate(zip(self.word_encodings, self.sent_encodings, self.mask_idxs)):\n",
    "            predictions =[]\n",
    "            candidate_input_ids = torch.stack([inp_ids['input_ids'].squeeze(0) for inp_ids in s]) #we create batch so instead do precition one by one, the model can predict the whole batch, we create a batch for each sentence \n",
    "            candidate_attention_masks = torch.stack([am['attention_mask'].squeeze(0) for am in s])\n",
    "            candidate_logits = self.model(candidate_input_ids, attention_mask=candidate_attention_masks).logits #where logits is  raw output of the model -> prediction\n",
    "            # -> output shape: 3 * num of tokens*vocab size, e.g. a prediction over the vocabulary for each token in each candidate question\n",
    "            # -> probability distribution over the whole vocab size\n",
    "            for idx, (token, mask_idxs) in enumerate(zip(w, m)): #for each of the 3 candidate sentences, we need to pick out the token that we masked in the sentence\n",
    "                mask_token_logits = candidate_logits[idx, mask_idxs, token] # here we want to find the raw prediction for the candidate word\n",
    "                candidate_score = float(torch.mean(mask_token_logits)) #if we have more than one mask this is our \"pseudo accuracy\"\n",
    "                predictions.append(candidate_score)\n",
    "            #print(f\"iprediction: {q_idx}, values: {predictions}\")\n",
    "            output.append(np.argmax(predictions) + 1) #start the keys for the choices at 1 as well > returns the choice that is chosen as an answer, we don't need that\n",
    "        #print(output)\n",
    "        return output\n",
    "    \n",
    "    #Function to see how often the biased words were chosen.\n",
    "    def get_bias(self,predictions):\n",
    "        biased, unbiased, unrelated = 0, 0, 0\n",
    "        for pred in predictions:\n",
    "            if pred == 1:\n",
    "                biased +=1\n",
    "            if pred == 2:\n",
    "                unbiased += 1\n",
    "            if pred == 3:\n",
    "                unrelated += 1\n",
    "        print(f\"biased: {biased}\")\n",
    "        print(f\"unbiased: {unbiased}\")\n",
    "        print(f\"unrelated: {unrelated}\")\n",
    "        self.print_graph(biased, unbiased, unrelated)\n",
    "    \n",
    "    def print_graph(self, biased, unbiased, unrelated):\n",
    "        data = {\n",
    "            'Biased':biased,\n",
    "            'Unbiased':unbiased,\n",
    "            'Unrelated':unrelated\n",
    "        }\n",
    "        courses = list(data.keys())\n",
    "        values = list(data.values())\n",
    "        \n",
    "        fig = plt.figure(figsize = (10, 5))\n",
    "        \n",
    "        # creating the bar plot\n",
    "        plt.bar(courses, values, color ='maroon',\n",
    "                width = 0.4)\n",
    "        \n",
    "        plt.xlabel(\"Choices\")\n",
    "        plt.ylabel(\"Number of sentence\")\n",
    "        plt.title(f\"Intrasentence test - {self.model_name} (Pre-trained)\")\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the intrasentence evaluator on the pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/mae/.cache/huggingface/hub/models--bert-large-uncased/snapshots/80792f8e8216b29f3c846b653a0ff0a37c210431/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biased: 7\n",
      "unbiased: 12\n",
      "unrelated: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "choices = {'bias':1, 'unbiased':2,'unrelated':3} \n",
    "file_path = 'dataset/testing_data_intra.csv' #\"drive/MyDrive/Final_templates.csv\"#\"drive/MyDrive/New_templates.csv\"\n",
    "model_name = 'bert-large-uncased'\n",
    "templates = pd.read_csv(file_path, sep=\";\")\n",
    "evaluator = IntrasentenceEvaluator(templates.copy(), choices, model_name, trainer.model)\n",
    "evaluator.run_model_and_evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c431e0593e1ee77f96bd6f746b63b987ead1ae8f9402a6438f4058638187923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
