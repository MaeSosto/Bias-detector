{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=8N-nM3QW7O0\n",
    "- https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
    "- https://github.com/curiousily/Getting-Things-Done-with-Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.13.0\n",
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "# Set the device      \n",
    "device = \"mps\" if torch.backends.mps.is_available() else torch.device(\"cuda\") if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117136bf0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_text = \"I love completing my todos! Best app ever!!!\"\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
      "   Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
      "Token IDs: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/mae/opt/miniconda3/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding = tokenizer.encode_plus(\n",
    "  sample_txt,\n",
    "  max_length=32,\n",
    "  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',  # Return PyTorch tensors\n",
    ")\n",
    "\n",
    "encoding.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-87-790fd5ed6898>:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot(token_lens)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "\n",
    "token_lens = []\n",
    "df = pd.read_csv(\"sentiment_dataset/test.csv\")\n",
    "df.head()\n",
    "\n",
    "for txt in df.sentence:\n",
    "    tokens = tokenizer.encode(txt, max_length=512)\n",
    "    token_lens.append(len(tokens))\n",
    "\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 20]);\n",
    "plt.xlabel('Token count')\n",
    "MAX_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPReviewDataset(Dataset):\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "      self.reviews = reviews\n",
    "      self.targets = targets\n",
    "      self.tokenizer = tokenizer\n",
    "      self.max_len = max_len\n",
    "      \n",
    "    def __len__(self):\n",
    "       return len(self.reviews)\n",
    "   \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            review,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'review_text': review,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(\n",
    "  df,\n",
    "  test_size=0.1,\n",
    "  random_state=RANDOM_SEED\n",
    ")\n",
    "df_val, df_test = train_test_split(\n",
    "  df_test,\n",
    "  test_size=0.5,\n",
    "  random_state=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 17\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m DataLoader(\n\u001b[1;32m     10\u001b[0m         ds,\n\u001b[1;32m     11\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     12\u001b[0m         num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[1;32m     13\u001b[0m     )\n\u001b[1;32m     15\u001b[0m BATCH_SIZE \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m\n\u001b[0;32m---> 17\u001b[0m train_data_loader \u001b[39m=\u001b[39m create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n\u001b[1;32m     18\u001b[0m val_data_loader \u001b[39m=\u001b[39m create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n\u001b[1;32m     19\u001b[0m test_data_loader \u001b[39m=\u001b[39m create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
      "Cell \u001b[0;32mIn[90], line 3\u001b[0m, in \u001b[0;36mcreate_data_loader\u001b[0;34m(df, tokenizer, max_len, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_data_loader\u001b[39m(df, tokenizer, max_len, batch_size):\n\u001b[1;32m      2\u001b[0m     ds \u001b[39m=\u001b[39m GPReviewDataset(\n\u001b[0;32m----> 3\u001b[0m         reviews\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39mto_numpy(),\n\u001b[1;32m      4\u001b[0m         targets\u001b[39m=\u001b[39mdf\u001b[39m.\u001b[39msentiment\u001b[39m.\u001b[39mto_numpy(),\n\u001b[1;32m      5\u001b[0m         tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m      6\u001b[0m         max_len\u001b[39m=\u001b[39mmax_len\n\u001b[1;32m      7\u001b[0m     )\n\u001b[1;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m DataLoader(\n\u001b[1;32m     10\u001b[0m         ds,\n\u001b[1;32m     11\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     12\u001b[0m         num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m\n\u001b[1;32m     13\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[39mand\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_axis\u001b[39m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__getattribute__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = GPReviewDataset(\n",
    "        reviews=df.content.to_numpy(),\n",
    "        targets=df.sentiment.to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "data = next(iter(train_data_loader))\n",
    "print(data['input_ids'].shape)\n",
    "print(data['attention_mask'].shape)\n",
    "print(data['targets'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "last_hidden_state, pooled_output = bert_model(\n",
    "  input_ids=encoding['input_ids'],\n",
    "  attention_mask=encoding['attention_mask']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(SentimentClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, pooled_output = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentimentClassifier(len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    model = model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "    outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask\n",
    "    )\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    correct_predictions += torch.sum(preds == targets)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "        \n",
    "            outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "        \n",
    "            loss = loss_fn(outputs, targets)\n",
    "        \n",
    "            correct_predictions += torch.sum(preds == targets)\n",
    "            losses.append(loss.item())\n",
    "    \n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(df_train)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    val_acc, val_loss = eval_model(\n",
    "        model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(df_val)\n",
    "    )\n",
    "\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_review = tokenizer.encode_plus(\n",
    "#     review_text,\n",
    "#     max_length=20,\n",
    "#     add_special_tokens=True,\n",
    "#     return_token_type_ids=False,\n",
    "#     pad_to_max_length=True,\n",
    "#     return_attention_mask=True,\n",
    "#     return_tensors='pt',\n",
    "# )\n",
    "\n",
    "# input_ids = encoded_review['input_ids'].to(device)\n",
    "# attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "# output = model(input_ids, attention_mask)\n",
    "# _, prediction = torch.max(output, dim=1)\n",
    "\n",
    "# print(f'Review text: {review_text}')\n",
    "# print(f'Sentiment  : {class_names[prediction]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c431e0593e1ee77f96bd6f746b63b987ead1ae8f9402a6438f4058638187923"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
